#!/usr/bin/python
# -*- encoding: utf-8; py-indent-offset: 4 -*-

factory_settings["ps_default_levels"] = {
    "levels" : (1, 1, 99999, 99999),
}

def solaris_inventory_ps_common(invdata, invrules, info):
    inventory = []
    entries = []

    # Handle new WATO style inventory rules
    for rule in invrules:
        taglist, hostlist = rule[1:3]
        if len(rule) >= 4:
            options = rule[3]
            if options.get("disabled"):
                continue

        # Filter out entries with do not match our current host
        if not hosttags_match_taglist(tags_of_host(g_hostname), taglist) \
           or not in_extraconf_hostlist(hostlist, g_hostname):
            continue

        v = rule[0]

        entries.append((v['descr'], v['match'],  v['levels']))

    for servicedesc, pattern, levels   in entries:
        num_perc_s = servicedesc.count("%s")
        i_servicedesc = servicedesc
        for line in info:
            # First entry in line is the node name or None for non-clusters
            ps = line[1:]
            matches = solaris_process_matches(ps, pattern)
            if matches != False:
                if matches == True:
                    inv_keys = {
                        "process" : pattern,
                        "levels" : levels,
                    }
                    inv = ( i_servicedesc, inv_keys )
                    if inv not in inventory:
                        inventory.append(inv)

                elif len(matches) < num_perc_s:
                    raise MKGeneralException("Invalid entry in inventory_processes: service description '%s' contains "
                            "%d times '%%s', but regular expression '%s' contains only %d subexpression(s)." % \
                            (servicedesc, num_perc_s, pattern, len(matches)))

                # New in 1.2.2b4: Alle %1, %2, etc. to be replaced with first, second, ...
                # group. This allows a reordering of the matched groups
                else:
                    for nr, group in enumerate(matches):
                        i_servicedesc = i_servicedesc.replace("%%%d" % (nr+1), group)

                # It is allowed (1.1.4) that the pattern contains more subexpressions then the
                # service description. In that case only the first subexpressions are used as
                # item.
                    i_servicedesc = i_servicedesc % tuple(matches[:num_perc_s])

                # Problem here: We need to instantiate all subexpressions
                # with their actual values of the found process.
                    i_pattern = instantiate_regex_pattern(pattern, matches)
                    inv_keys = {
                        "process" : i_pattern,
                    }
                # default_params is either a clean dict with optional parameters to set as default
                # or - from version 1.2.4 - the dict from the rule itself. In the later case
                # we need o remove the keys that do not specify default parameters
                #for  value in levels:
                    inv_keys.setdefault("levels", levels)
                    inv = ( i_servicedesc, inv_keys )

                    if inv not in inventory:
                        inventory.append(inv)

    return inventory

def solaris_process_matches(ps, procname):
    # procname is either:
    # 1. a string beginning with ~. Then it is interpreted as regular expression
    # that must match the *beginning* of the process line. Please check the output of
    # check_mk -d HOSTNAME. Note: groups of whitespaces are reduced to one single
    # whitespace!
    # 2. a string *not* beginning with ~: It must be equal to the first column
    # in the process table (i.e. the process name). No regular expressions are
    # applied. A simple string compare is done.

    # agent might output username in brackets in the first columns

    if not procname:
        return ()

    elif not procname.startswith("~"):
        pat = (" ".join(ps))
        if pat != procname:
            return False
        else :
            return True
    else:
        pattern = procname.replace("~", "")
        reg = compiled_regexes.get(pattern)
        if not reg:
            reg = re.compile(pattern)
            compiled_regexes[pattern] = reg
        matchobject = reg.match(" ".join(ps))
        if matchobject:
            return [ g and g or "" for g in matchobject.groups() ]
    return False

def solaris_check_ps_common(item, params, info ):
    now = time.time()
    info_name = "processes"
    if type(params) in (list, tuple):
        if len(params) == 5:
            procname, warnmin, okmin, okmax, warnmax = params
            user = None
        elif len(params) == 6:
            procname, user, warnmin, okmin, okmax, warnmax = params
        params = {
            "process" : procname,
            "levels" :  (warnmin, okmin, okmax, warnmax),
        }
        if user != None:
            params["user"] = user
    elif "okmin" in params or "warnmin" in params or "okmax" in params or "warnmax" in params:
        params["levels"] = (
            params.get("warnmin", 1),
            params.get("okmin", 1),
            params.get("okmax", 99999),
            params.get("warnmax", 99999),
        )

    count = 0

    for line in info:
        ps = line[1:]
        if solaris_process_matches(ps, params.get("process")) != False:
            count += 1

    warnmin, okmin, okmax, warnmax = params["levels"]
    perfdata = [ ("count", count, okmax+1, warnmax+1, 0) ]

    infotext = "%d %s" % (count, info_name)

    state = 0
    if count > warnmax or count < warnmin:
        state = 2
        infotext += " (ok from %d to %d)(!!)" % (okmin, okmax)
    elif count > okmax or count < okmin:
        state = 1
        infotext += " (ok from %d to %d)(!)" % (okmin, okmax)

    return state, infotext, perfdata

def spgs_parse_info(info):
  parsed_data = {}

  for line in info:
    # Skip until "SUMMARY LINE"
    if "SUMMARY" not in line:
      continue
    else:
      for line in info:
        if not len(line) == 9:
          continue
  
        if not line[8] in parsed_data.keys():
          parsed_data[line[8]] = { 
          'Integer_Pipeline': [], 
          'Floating_Point_Unit': [], 
          'System': [], 
          'Data_Pipe_to_memory': [] 
        }
  
        parsed_data[line[8]][line[1]].append( { 
          'hwmin': savefloat(line[2]), 
          'hwavg': savefloat(line[3]), 
          'hwmax': savefloat(line[4]), 
          'swmin': savefloat(line[5]), 
          'swavg': savefloat(line[6]), 
          'swmax': savefloat(line[7]) 
        })

  return parsed_data

def spgs_group_info(parsed_data):

  grouped_data = {}

  for i in parsed_data.keys():
    if len(parsed_data[i]['System']) != 0 or len(parsed_data[i]['Data_Pipe_to_memory']) != 0:
      continue
  
    fpuavgs = map(lambda x: x['hwavg'], parsed_data[i]['Floating_Point_Unit'])
    ipavgs  = map(lambda x: x['hwavg'], parsed_data[i]['Integer_Pipeline'])
    swavgs  = map(lambda x: x['swavg'], parsed_data[i]['Floating_Point_Unit'] + parsed_data[i]['Integer_Pipeline'])
    swmaxes = map(lambda x: x['swmax'], parsed_data[i]['Floating_Point_Unit'] + parsed_data[i]['Integer_Pipeline'])
  
    grouped_data[i] = { 
      'fpuavg': sum(fpuavgs)/len(fpuavgs),
      'fpumax': max(map(lambda x: x['hwmax'], parsed_data[i]['Floating_Point_Unit'])), 
      'ipavg':  sum(ipavgs)/len(ipavgs),
      'ipmax':  max(map(lambda x: x['hwmax'], parsed_data[i]['Integer_Pipeline'])), 
      'swavg':  sum(swavgs)/len(swavgs), 
      'swmax':  max(swmaxes) 
    }

  return grouped_data

# vim: tabstop=4 expandtab shiftwidth=4 softtabstop=4
